{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Multiple Models in a Python 3 Notebook\n",
    "\n",
    "##  Introduction\n",
    "\n",
    "The purpose of this example is to compare the performance of machine learning models within a Jupyter notebook. We will use the classic 1974 *Motor Trend* car road tests (`mtcars`) dataset to fit and evaluate three models:\n",
    "1. A linear model using all variables\n",
    "1. A linear model after variable selection\n",
    "1. A Gradient Boosting Machine (GBM) model \n",
    "\n",
    "This is a lightly-modified version of a [notebook](https://gallery.cortanaintelligence.com/Notebook/Evaluating-Multiple-Models-6) originally created by a Microsoft employee for distribution on the [Cortana Intelligence Gallery](https://gallery.cortanaintelligence.com/). [Python 2 and R versions](https://notebooks.azure.com/library/eSJDgAFMXAY) of this notebook are also available on Azure Notebooks.\n",
    "\n",
    "## Outline\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Prepare Data](#Prepare-Data)\n",
    "- [Fit Models](#Fit-Models)\n",
    "   - [Linear Model](#Linear-Model)\n",
    "   - [Linear Model with Feature Selection](#Linear-Model-with-Feature-Selection)\n",
    "   - [Gradient Boosting Machine Regression Model](#Gradient-Boosting-Machine-Regression-Model)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "We'll start by loading the `mtcars` sample dataset and displaying its description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiated datasets repo at: C:\\Users\\Ari Wibisono\\.pydataset/\n",
      "mtcars\n",
      "\n",
      "PyDataset Documentation (adopted from R Documentation. The displayed examples are in R)\n",
      "\n",
      "## Motor Trend Car Road Tests\n",
      "\n",
      "### Description\n",
      "\n",
      "The data was extracted from the 1974 _Motor Trend_ US magazine, and comprises\n",
      "fuel consumption and 10 aspects of automobile design and performance for 32\n",
      "automobiles (1973–74 models).\n",
      "\n",
      "### Usage\n",
      "\n",
      "    mtcars\n",
      "\n",
      "### Format\n",
      "\n",
      "A data frame with 32 observations on 11 variables.\n",
      "\n",
      "[, 1]\n",
      "\n",
      "mpg\n",
      "\n",
      "Miles/(US) gallon\n",
      "\n",
      "[, 2]\n",
      "\n",
      "cyl\n",
      "\n",
      "Number of cylinders\n",
      "\n",
      "[, 3]\n",
      "\n",
      "disp\n",
      "\n",
      "Displacement (cu.in.)\n",
      "\n",
      "[, 4]\n",
      "\n",
      "hp\n",
      "\n",
      "Gross horsepower\n",
      "\n",
      "[, 5]\n",
      "\n",
      "drat\n",
      "\n",
      "Rear axle ratio\n",
      "\n",
      "[, 6]\n",
      "\n",
      "wt\n",
      "\n",
      "Weight (lb/1000)\n",
      "\n",
      "[, 7]\n",
      "\n",
      "qsec\n",
      "\n",
      "1/4 mile time\n",
      "\n",
      "[, 8]\n",
      "\n",
      "vs\n",
      "\n",
      "V/S\n",
      "\n",
      "[, 9]\n",
      "\n",
      "am\n",
      "\n",
      "Transmission (0 = automatic, 1 = manual)\n",
      "\n",
      "[,10]\n",
      "\n",
      "gear\n",
      "\n",
      "Number of forward gears\n",
      "\n",
      "[,11]\n",
      "\n",
      "carb\n",
      "\n",
      "Number of carburetors\n",
      "\n",
      "### Source\n",
      "\n",
      "Henderson and Velleman (1981), Building multiple regression models\n",
      "interactively. _Biometrics_, **37**, 391–411.\n",
      "\n",
      "### Examples\n",
      "\n",
      "    require(graphics)\n",
      "    pairs(mtcars, main = \"mtcars data\")\n",
      "    coplot(mpg ~ disp | as.factor(cyl), data = mtcars,\n",
      "           panel = panel.smooth, rows = 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pydataset --disable-pip-version-check -q \n",
    "import pydataset\n",
    "from pydataset import data\n",
    "df = data('mtcars')\n",
    "data('mtcars', show_doc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly examine the distribution of values and first few rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.090625</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>230.721875</td>\n",
       "      <td>146.687500</td>\n",
       "      <td>3.596563</td>\n",
       "      <td>3.217250</td>\n",
       "      <td>17.848750</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>2.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.026948</td>\n",
       "      <td>1.785922</td>\n",
       "      <td>123.938694</td>\n",
       "      <td>68.562868</td>\n",
       "      <td>0.534679</td>\n",
       "      <td>0.978457</td>\n",
       "      <td>1.786943</td>\n",
       "      <td>0.504016</td>\n",
       "      <td>0.498991</td>\n",
       "      <td>0.737804</td>\n",
       "      <td>1.6152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>1.513000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.425000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>120.825000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>2.581250</td>\n",
       "      <td>16.892500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>196.300000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>17.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.800000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>5.424000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mpg        cyl        disp          hp       drat         wt  \\\n",
       "count  32.000000  32.000000   32.000000   32.000000  32.000000  32.000000   \n",
       "mean   20.090625   6.187500  230.721875  146.687500   3.596563   3.217250   \n",
       "std     6.026948   1.785922  123.938694   68.562868   0.534679   0.978457   \n",
       "min    10.400000   4.000000   71.100000   52.000000   2.760000   1.513000   \n",
       "25%    15.425000   4.000000  120.825000   96.500000   3.080000   2.581250   \n",
       "50%    19.200000   6.000000  196.300000  123.000000   3.695000   3.325000   \n",
       "75%    22.800000   8.000000  326.000000  180.000000   3.920000   3.610000   \n",
       "max    33.900000   8.000000  472.000000  335.000000   4.930000   5.424000   \n",
       "\n",
       "            qsec         vs         am       gear     carb  \n",
       "count  32.000000  32.000000  32.000000  32.000000  32.0000  \n",
       "mean   17.848750   0.437500   0.406250   3.687500   2.8125  \n",
       "std     1.786943   0.504016   0.498991   0.737804   1.6152  \n",
       "min    14.500000   0.000000   0.000000   3.000000   1.0000  \n",
       "25%    16.892500   0.000000   0.000000   3.000000   2.0000  \n",
       "50%    17.710000   0.000000   0.000000   4.000000   2.0000  \n",
       "75%    18.900000   1.000000   1.000000   4.000000   4.0000  \n",
       "max    22.900000   1.000000   1.000000   5.000000   8.0000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mazda RX4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda RX4 Wag</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datsun 710</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet 4 Drive</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet Sportabout</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "Mazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "Mazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "Datsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "Hornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "                   carb  \n",
       "Mazda RX4             4  \n",
       "Mazda RX4 Wag         4  \n",
       "Datsun 710            1  \n",
       "Hornet 4 Drive        1  \n",
       "Hornet Sportabout     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for the machine learning models in this tutorial will be to predict each car's gas mileage (`mpg`) from the car's other features.\n",
    "\n",
    "We will split the records into training and test datasets: each model will be fitted using the training data, and evaluated using the withheld test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into features available for prediction (X) and value to predict (y)\n",
    "y = df['mpg'].values\n",
    "X = df.drop('mpg', 1).values\n",
    "feature_names = df.drop('mpg', 1).columns\n",
    "\n",
    "# save 30% of the records for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=123)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the description above, the number of predictive features available in this dataset (10) is comparable to the number of records (22). Such conditions tend to produce overfitted models that give exceptional predictions on their own training data, but poor predictions on the withheld test data. We will see an example of an overfitted model below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models\n",
    "### Linear Model\n",
    "The following lines of code fit a linear model (without regularization) using all of the original features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we print the R-squared value for the true vs. predicted `mpg` values in the *training* set. We also show the fitted coefficients for different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value for the training set is: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>-96.037501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cyl</td>\n",
       "      <td>-5.777114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disp</td>\n",
       "      <td>0.183642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hp</td>\n",
       "      <td>-0.245128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drat</td>\n",
       "      <td>20.683140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wt</td>\n",
       "      <td>6.713631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qsec</td>\n",
       "      <td>5.128808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vs</td>\n",
       "      <td>-12.882279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>am</td>\n",
       "      <td>34.980730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gear</td>\n",
       "      <td>-19.251219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>carb</td>\n",
       "      <td>9.163095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Coefficient\n",
       "0   intercept   -96.037501\n",
       "1         cyl    -5.777114\n",
       "2        disp     0.183642\n",
       "3          hp    -0.245128\n",
       "4        drat    20.683140\n",
       "5          wt     6.713631\n",
       "6        qsec     5.128808\n",
       "7          vs   -12.882279\n",
       "8          am    34.980730\n",
       "9        gear   -19.251219\n",
       "10       carb     9.163095"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# print R^2 for the training set\n",
    "print('The R-squared value for the training set is: {:0.4f}'.format(r2_score(y_train, lm.predict(X_train))))\n",
    "\n",
    "# print intercept and coefficients\n",
    "param_df = pd.DataFrame({\"Coefficient\": [lm.intercept_] + list(lm.coef_),\n",
    "                         \"Feature\": ['intercept'] + list(feature_names)})\n",
    "param_df[['Feature', 'Coefficient']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model performs very well on the training data to which it was fitted. (Predictions of the model account for 89% of the variance in `mpg` values.) Some of the feature coefficients may reflect our intuition: for example, heavy cars tend to have worse gas mileage ($\\beta_{\\textrm{wt}} = -5.0$), and cars with manual transmissions tend to have better gas mileage ($\\beta_{\\textrm{am}} = 5.2$).\n",
    "\n",
    "Now, let's check the model's performance on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression, all variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-15.887973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>15.632566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <td>22.142005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Absolute Error</th>\n",
       "      <td>3.630851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Squared Error</th>\n",
       "      <td>16.887973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Linear Regression, all variables\n",
       "R-squared                                      -15.887973\n",
       "Mean Absolute Error                             15.632566\n",
       "Root Mean Squared Error                         22.142005\n",
       "Relative Absolute Error                          3.630851\n",
       "Relative Squared Error                          16.887973"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = lm.predict(X_test)\n",
    "\n",
    "r_squared = r2_score(y_test, predicted)\n",
    "mae = np.mean(abs(predicted - y_test))\n",
    "rmse = np.sqrt(np.mean((predicted - y_test)**2))\n",
    "rae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\n",
    "rse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n",
    "\n",
    "# Create a data frame for storing results from each model\n",
    "summary_df = pd.DataFrame(index = ['R-squared', 'Mean Absolute Error', 'Root Mean Squared Error',\n",
    "                                   'Relative Absolute Error', 'Relative Squared Error'])\n",
    "summary_df['Linear Regression, all variables'] = [r_squared, mae, rmse, rae, rse]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the R-squared value for true vs. predicted `mpg` of the test set is much lower than it was for the training set. (Granted, our test set is not very large, so some fluctuation is expected.) This is indicative of model overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model with Feature Selection\n",
    "\n",
    "One way to reduce overfitting is to remove some predictive features from the model. Ideally we would be able to examine many or all possible subsets of features and select the subset of features that gives the best performance, but that is usually impractical due to the large number of possible subsets. A common alternative is to start from the full list of features and recursively remove one that seems to be contributing least to the model's performance (i.e., the feature whose removal has the least negative/most positive effect on model performance). This process is called recursive feature elimination (RFE).\n",
    "\n",
    "RFE fits many models and compares their performance: it therefore requires both training and testing data. We would like to reserve the test dataset we created earlier to fairly compare all models, so RFE will need to set aside some records in the `X_train`/`y_train` dataset for its own round of testing. Fortunately, this is easily done with `scikit-learn`'s cross-validation functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 3\n",
      "Features selected: drat, am, gear\n",
      "Suggested order of feature removal: qsec, cyl, disp, vs, wt, hp, carb, drat, am, gear\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAF+CAYAAABqLmczAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIsnSbEQQgghhLB4/wezkogyylqpmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1920dff518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "\n",
    "# scale each feature to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# recursive feature elimination with cross validation, using r-squared score as metric\n",
    "lm = LinearRegression()  # using a linear model as before\n",
    "rfecv = RFECV(estimator=lm, step=1, cv=5) \n",
    "rfecv.fit(X_scaled, y_train)\n",
    "\n",
    "# print the optimal number of features\n",
    "print('Optimal number of features: {}'.format(rfecv.n_features_))\n",
    "\n",
    "# save the selected features\n",
    "print('Features selected: {}'.format(', '.join(np.array(feature_names)[rfecv.support_].tolist())))\n",
    "\n",
    "# get the feature elimination order\n",
    "ranked_features, _ = zip(*sorted(zip(feature_names, rfecv.ranking_.tolist()),\n",
    "                                 key=lambda x: x[1],\n",
    "                                 reverse=True))\n",
    "print('Suggested order of feature removal: {}'.format(', '.join(ranked_features)))\n",
    "\n",
    "# plot number of features vs. scores\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the performance of the model (on the cross-validation testing set) tends to improve as we reduce the number of features in the model. As expected, weight and presence of an automatic transmission are among the features which would be removed last (since they are relevant for predicting gas mileage), whereas the number of forward gears is not so relevant.\n",
    "\n",
    "We can now fit a linear model using only the selected features, and assess its performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression, all variables</th>\n",
       "      <th>Linear Regression, selected variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-15.887973</td>\n",
       "      <td>-0.225340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>15.632566</td>\n",
       "      <td>4.943677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <td>22.142005</td>\n",
       "      <td>5.964259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Absolute Error</th>\n",
       "      <td>3.630851</td>\n",
       "      <td>1.148228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Squared Error</th>\n",
       "      <td>16.887973</td>\n",
       "      <td>1.225340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Linear Regression, all variables  \\\n",
       "R-squared                                      -15.887973   \n",
       "Mean Absolute Error                             15.632566   \n",
       "Root Mean Squared Error                         22.142005   \n",
       "Relative Absolute Error                          3.630851   \n",
       "Relative Squared Error                          16.887973   \n",
       "\n",
       "                         Linear Regression, selected variables  \n",
       "R-squared                                            -0.225340  \n",
       "Mean Absolute Error                                   4.943677  \n",
       "Root Mean Squared Error                               5.964259  \n",
       "Relative Absolute Error                               1.148228  \n",
       "Relative Squared Error                                1.225340  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subset = X_train[:, rfecv.support_]\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(X_train_subset, y_train)\n",
    "\n",
    "X_test_part = X_test[:, rfecv.support_]\n",
    "predicted = lm2.predict(X_test_part)\n",
    "\n",
    "r_squared = r2_score(y_test, predicted)\n",
    "mae = np.mean(abs(predicted - y_test))\n",
    "rmse = np.sqrt(np.mean((predicted - y_test)**2))\n",
    "rae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\n",
    "rse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n",
    "\n",
    "summary_df['Linear Regression, selected variables'] = [r_squared, mae, rmse, rae, rse]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's performance on the withheld test set improved (by all metrics) after the majority of features were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine Regression Model\n",
    "\n",
    "Before fitting the gradient boosting model, we need to estimate some parameters and we'll do this using cross-validation along with grid search. The following code box may take some time to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from time import time\n",
    "\n",
    "# We will try all combinations of these possible parameter values\n",
    "tuned_params = {'n_estimators': [5000, 10000], \n",
    "                'max_depth': [2,4], \n",
    "                'min_samples_split': [1, 2],\n",
    "                'learning_rate': [0.001, 0.01]}\n",
    "gscv = GridSearchCV(GradientBoostingRegressor(loss = 'ls', random_state=0), \n",
    "                    tuned_params, cv=5, scoring='mean_squared_error')\n",
    "\n",
    "# th\n",
    "start = time()\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "print('The grid cross validation lasted {:0.1f} seconds'.format(time() - start))\n",
    "print('Best parameters set found on development set:\\n\\t{}'.format(\n",
    "        ', '.join(['{}: {}'.format(i,j) for i,j in gscv.best_params_.items()])))\n",
    "print('Grid scores on development set:')\n",
    "for params, mean_score, scores in gscv.grid_scores_:\n",
    "    print('\\t{:0.2f} (+/- {:0.2f}) for {}'.format(mean_score,\n",
    "                                      scores.std() * 2,\n",
    "                                      ', '.join(['{}: {}'.format(i, j) for i, j in params.items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit the GBM model with the parameters that gave the best performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with the best set of parameter values\n",
    "params = gscv.best_params_\n",
    "params['random_state'] = 123\n",
    "params['loss'] = 'ls'\n",
    "gbm = GradientBoostingRegressor(**params)\n",
    "\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the model's performance on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gbm.predict(X_test)\n",
    "\n",
    "r_squared = r2_score(y_test, predicted)\n",
    "mae = np.mean(abs(predicted - y_test))\n",
    "rmse = np.sqrt(np.mean((predicted - y_test)**2))\n",
    "rae = np.mean(abs(predicted - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\n",
    "rse = np.mean((predicted - y_test)**2) / np.mean((y_test - np.mean(y_test))**2)\n",
    "\n",
    "summary_df['Gradient Boosted Machine Regression'] = [r_squared, mae, rmse, rae, rse]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variable importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = gbm.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "index = np.arange(len(feature_names))\n",
    "bar_width = 0.5\n",
    "plt.bar(index, feature_importance[sorted_idx], color='black', alpha=0.5)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('importance')\n",
    "plt.title('Feature importance')\n",
    "plt.xticks(index + bar_width, np.array(feature_names)[sorted_idx])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features which were eliminated later by RFE (like `am`) have low feature importance in the GBM model.\n",
    "\n",
    "Let's assess whether our GBM model's performance is likely to be limited by the number of estimators used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot deviance for training set and test set\n",
    "test_score = np.zeros(params['n_estimators'])\n",
    "\n",
    "for j, y_pred in enumerate(gbm.staged_decision_function(X_test)):\n",
    "    test_score[j] = gbm.loss_(y_test, y_pred)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, gbm.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above demonstrates that the loss function plateaus well before we reach the total number of estimators used by our model. We could likely get away with using fewer estimators for a speed improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The following table compares the performance of the three models. Variable selection using RFE improved the performance of the linear regression model by all metrics. The GBM model performed comparably to linear regression with variable selection. (We will avoid reading too deeply into the differences in metrics, because the test dataset is so small.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
